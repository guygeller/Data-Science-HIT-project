{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ce0386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup  \n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import hashlib\n",
    "import time\n",
    "from random import randint\n",
    "from time import sleep\n",
    "import re\n",
    "from fp.fp import FreeProxy\n",
    "from lxml.html import fromstring\n",
    "from itertools import cycle\n",
    "import traceback\n",
    "from csv import writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a982dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Connection': 'keep-alive',\n",
    "    'sec-ch-ua': '\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"96\", \"Google Chrome\";v=\"96\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'Sec-Fetch-Site': 'none',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-User': '?1',\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Accept-Language': 'he-IL,he;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "}\n",
    "\n",
    "\n",
    "def load_soup_object(url_path):\n",
    "    page = requests.get(url_path, headers = headers)\n",
    "    #print(page)\n",
    "    return BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "488418de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## name, current alias, affiliation, marital status, gender,\n",
    "## height, weight, hair color, origin, living status, cause of death, reality, place of birth,\n",
    "## identity, citenzenship, education, creators, unusual features, occupation\n",
    "\n",
    "\n",
    "def time_convert(sec):\n",
    "    mins = sec // 60\n",
    "    sec = sec % 60\n",
    "    hours = mins // 60\n",
    "    mins = mins % 60\n",
    "    print(\"Time Lapsed = {0}:{1}:{2}\".format(int(hours),int(mins),sec))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28b092cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(columns = ['Name','Marital Status', 'Gender', 'Hair Color',\n",
    "                                    'Eye Color', 'Living status', 'Reality','Identity',\n",
    "                                    'Citenzenship','Appearnces', 'Year'])\n",
    "\n",
    "url_prefix = 'https://marvel.fandom.com'\n",
    "first_page = False\n",
    "\n",
    "start_time = time.time()\n",
    "next_page = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f56689d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "didn't wriet a row to csv\n",
      "An exception occurred during loading character page\n"
     ]
    }
   ],
   "source": [
    "soup = load_soup_object('https://marvel.fandom.com/wiki/Category:Characters?from=T%27Challa+%28Earth-000000000002992%29%0AT%27Challa+%28Earth-2992%29')\n",
    "not_last_page = True\n",
    "index = 0\n",
    "while not_last_page:\n",
    "    current_page_character_list = soup.find_all('div', {'class': 'category-page__members-wrapper'})\n",
    "    if first_page:\n",
    "        links = soup.find_all('a',  {'class': 'category-page__member-link'})[18:]\n",
    "        first_page = False\n",
    "    else:\n",
    "        links = soup.find_all('a',  {'class': 'category-page__member-link'})\n",
    "\n",
    "    for i,X in enumerate(links):\n",
    "        row = list()\n",
    "        #print(str(i) + \". \" + url_prefix + X.get('href'))\n",
    "        try:\n",
    "            character_page_soup = load_soup_object(url_prefix + X.get('href'))\n",
    "        except:\n",
    "            print(\"An exception occurred during loading character page\")\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Name'}) is not None:\n",
    "            if character_page_soup.find('div',  {'data-source': 'Name'}).find('div',  {'class': 'pi-data-value pi-font'}).a is not None:\n",
    "                name = character_page_soup.find('div',  {'data-source': 'Name'}).find('div',  {'class': 'pi-data-value pi-font'}).a\n",
    "                row.append(name.get_text().strip())\n",
    "            else:\n",
    "                name = character_page_soup.find('div',  {'data-source': 'Name'}).find('div',  {'class': 'pi-data-value pi-font'})\n",
    "                name.get_text().strip()\n",
    "                row.append(name.get_text().strip())\n",
    "        else:\n",
    "            row.append(None)\n",
    "\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'MaritalStatus'}) is not None:\n",
    "            if character_page_soup.find('div', {'data-source': 'MaritalStatus'}).a is not None: \n",
    "                m_status = character_page_soup.find('div', {'data-source': 'MaritalStatus'}).a\n",
    "                row.append(m_status.get_text().strip())\n",
    "            else:\n",
    "                row.append(None)\n",
    "        else:\n",
    "            row.append(None)\n",
    "\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Reality'}) is not None: \n",
    "            reality_content = character_page_soup.find('div',  {'data-source': 'Reality'}).find('div',  {'class': 'pi-data-value pi-font'}).get_text().strip()\n",
    "            row.append(reality_content)\n",
    "        else:\n",
    "            row.append(None)\n",
    "\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Gender'}) is not None:\n",
    "            if character_page_soup.find('div', {'data-source': 'Gender'}).a is not None:\n",
    "                gender = character_page_soup.find('div', {'data-source': 'Gender'}).a\n",
    "                row.append(gender.get_text().strip())\n",
    "            else:\n",
    "                row.append(None)\n",
    "        else:\n",
    "            row.append(None)\n",
    "\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Hair'}) is not None:\n",
    "            if character_page_soup.find('div', {'data-source': 'Hair'}).a is not None:\n",
    "                hair = character_page_soup.find('div', {'data-source': 'Hair'}).a\n",
    "                row.append(hair.get_text().strip())\n",
    "            else:\n",
    "                row.append(None)\n",
    "        else:\n",
    "            row.append(None)\n",
    "\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Eyes'}) is not None:\n",
    "            if character_page_soup.find('div', {'data-source': 'Eyes'}).a is not None:\n",
    "                eye = character_page_soup.find('div', {'data-source': 'Eyes'}).a\n",
    "                row.append(eye.get_text().strip())\n",
    "            else:\n",
    "                row.append(None)\n",
    "        else:\n",
    "            row.append(None)\n",
    "\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Status'}) is not None:\n",
    "            status = character_page_soup.find('div',{'data-source': 'Status'}).find_all('a')\n",
    "            row.append(status[0].get_text().strip())\n",
    "        else:\n",
    "            row.append(None)\n",
    "\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Identity'}) is not None:\n",
    "            if character_page_soup.find('div',  {'data-source': 'Identity'}).a is not None:\n",
    "                identity =  character_page_soup.find('div',  {'data-source': 'Identity'}).a.get_text().strip()\n",
    "                row.append(identity)\n",
    "            else:\n",
    "                row.append(None)\n",
    "        else:\n",
    "            row.append(None)\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Citizenship'}) is not None:\n",
    "            citizen_content = character_page_soup.find('div',  {'data-source': 'Citizenship'}).find('div',  {'class': 'pi-data-value pi-font'}).get_text().strip()\n",
    "            row.append(citizen_content)\n",
    "        else:\n",
    "            row.append(None)\n",
    "\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'First'}) is not None:\n",
    "            year_content = character_page_soup.find('div', {'data-source': 'First'}).find_all('a')\n",
    "            if(len(year_content) > 1):\n",
    "                year = character_page_soup.find('div', {'data-source': 'First'}).find_all('a')[1].get_text().strip().split()[-1]\n",
    "            else:\n",
    "                if len(character_page_soup.find('div', {'data-source': 'First'}).get_text().strip().split()) > 0:\n",
    "                    year = character_page_soup.find('div', {'data-source': 'First'}).get_text().strip().split()[-1]\n",
    "                    if 'Mentioned' in year:\n",
    "                        year = year[0:4]\n",
    "                    elif 'Carving' in year:\n",
    "                        year = year[0:4]\n",
    "                    elif 'Series' in year:\n",
    "                        year = year[0:4]\n",
    "                    else:\n",
    "                        year = character_page_soup.find('div', {'data-source': 'First'}).get_text().strip().split()[-1][:-1]\n",
    "                else:\n",
    "                    year = character_page_soup.find('div', {'data-source': 'First'}).get_text().strip()\n",
    "            row.append(year)\n",
    "        else:\n",
    "            row.append(None)\n",
    "\n",
    "\n",
    "        if character_page_soup.find('span',  {'id': 'See_Also'}) is not None:\n",
    "            appearnces_parent = character_page_soup.find('span', {'id': 'See_Also'}).parent\n",
    "            if appearnces_parent.next_sibling.next_sibling.find('li') is not None:\n",
    "                appearnces_content = appearnces_parent.next_sibling.next_sibling.find('li').get_text().strip().split()[0]\n",
    "                row.append(appearnces_content.split()[0])\n",
    "            else:\n",
    "                row.append(None)\n",
    "        else:\n",
    "            row.append(None)\n",
    "\n",
    "        series = pd.Series(row, index = dataframe.columns)\n",
    "        dataframe = dataframe.append(series, ignore_index=True)\n",
    "        \n",
    "        \n",
    "        with open(r'C:\\Users\\guyge\\Desktop\\data science\\Marvel HIT\\Data-Science-HIT-project\\Marvel CSV.csv', 'a', newline='') as f_object:  \n",
    "            # Pass the CSV  file object to the writer() function\n",
    "            writer_object = writer(f_object)\n",
    "            # Result - a writer object\n",
    "            # Pass the data in the list as an argument into the writerow() function\n",
    "            try:\n",
    "                writer_object.writerow(row)\n",
    "            except:\n",
    "                print(\"didn't wriet a row to csv\")\n",
    "            # Close the file object\n",
    "            f_object.close()\n",
    "\n",
    "   \n",
    "    if soup.find('a', {'class':'category-page__pagination-next'}) is not None:\n",
    "        next_page = soup.find('a', {'class':'category-page__pagination-next'}).get('href')\n",
    "        try:\n",
    "            soup = load_soup_object(next_page)\n",
    "        except:\n",
    "            print(\"An exception occurred during loading next page\")\n",
    "    \n",
    "    else:\n",
    "        not_last_page = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "202dd74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://marvel.fandom.com/wiki/Category:Characters?from=Zorr+%28Luphomoid%29+%28Earth-TRN517%29%0AZorr+%28Luphomoid%29+%28Earth-TRN517%29\n"
     ]
    }
   ],
   "source": [
    "print(next_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0d458b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Lapsed = 2:39:18.40448570251465\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "time_lapsed = end_time - start_time\n",
    "time_convert(time_lapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af6cb40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Hair Color</th>\n",
       "      <th>Eye Color</th>\n",
       "      <th>Living status</th>\n",
       "      <th>Reality</th>\n",
       "      <th>Identity</th>\n",
       "      <th>Citenzenship</th>\n",
       "      <th>Appearnces</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T'Challa</td>\n",
       "      <td>None</td>\n",
       "      <td>Earth-2992</td>\n",
       "      <td>Male</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Deceased</td>\n",
       "      <td>Public</td>\n",
       "      <td>Wakandan</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T'Challa</td>\n",
       "      <td>Single</td>\n",
       "      <td>Earth-3131</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Public</td>\n",
       "      <td>Wakandan</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T'Challa</td>\n",
       "      <td>Single</td>\n",
       "      <td>Earth-4321</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>None</td>\n",
       "      <td>Deceased</td>\n",
       "      <td>Public</td>\n",
       "      <td>Wakandan</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T'Challa</td>\n",
       "      <td>None</td>\n",
       "      <td>Earth-5631</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>None</td>\n",
       "      <td>Alive</td>\n",
       "      <td>None</td>\n",
       "      <td>Wakandan</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T'Challa</td>\n",
       "      <td>Single</td>\n",
       "      <td>Earth-6109</td>\n",
       "      <td>Male</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Secret</td>\n",
       "      <td>Wakandian</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9269</th>\n",
       "      <td>Äkräs</td>\n",
       "      <td>None</td>\n",
       "      <td>Earth-616</td>\n",
       "      <td>Male</td>\n",
       "      <td>Brown</td>\n",
       "      <td>None</td>\n",
       "      <td>Alive</td>\n",
       "      <td>No Dual</td>\n",
       "      <td>Taivas</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9270</th>\n",
       "      <td>[1]</td>\n",
       "      <td>Single</td>\n",
       "      <td>Earth-TRN517</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>None</td>\n",
       "      <td>Alive</td>\n",
       "      <td>No Dual</td>\n",
       "      <td>Battlerealm[1]</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9271</th>\n",
       "      <td>Ériu</td>\n",
       "      <td>None</td>\n",
       "      <td>Earth-616</td>\n",
       "      <td>Female</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Alive</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2009</td>\n",
       "      <td>Mentions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9272</th>\n",
       "      <td>Ögedei Khan</td>\n",
       "      <td>Married</td>\n",
       "      <td>Earth-616</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Black</td>\n",
       "      <td>Deceased</td>\n",
       "      <td>No Dual</td>\n",
       "      <td>Mongolian</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9273</th>\n",
       "      <td>Øde</td>\n",
       "      <td>None</td>\n",
       "      <td>Earth-616</td>\n",
       "      <td>Male</td>\n",
       "      <td>No Hair At All</td>\n",
       "      <td>Black</td>\n",
       "      <td>Deceased</td>\n",
       "      <td>No Dual</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9274 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name Marital Status        Gender Hair Color       Eye Color  \\\n",
       "0        T'Challa           None    Earth-2992       Male            None   \n",
       "1        T'Challa         Single    Earth-3131       Male           Black   \n",
       "2        T'Challa         Single    Earth-4321       Male           Black   \n",
       "3        T'Challa           None    Earth-5631       Male           Black   \n",
       "4        T'Challa         Single    Earth-6109       Male            None   \n",
       "...           ...            ...           ...        ...             ...   \n",
       "9269        Äkräs           None     Earth-616       Male           Brown   \n",
       "9270          [1]         Single  Earth-TRN517       Male           White   \n",
       "9271         Ériu           None     Earth-616     Female            None   \n",
       "9272  Ögedei Khan        Married     Earth-616       Male           Black   \n",
       "9273          Øde           None     Earth-616       Male  No Hair At All   \n",
       "\n",
       "     Living status   Reality Identity    Citenzenship Appearnces      Year  \n",
       "0             None  Deceased   Public        Wakandan       2004         1  \n",
       "1            Brown     Alive   Public        Wakandan       2002         1  \n",
       "2             None  Deceased   Public        Wakandan       2003         1  \n",
       "3             None     Alive     None        Wakandan       2007         1  \n",
       "4             None     Alive   Secret       Wakandian       2006         2  \n",
       "...            ...       ...      ...             ...        ...       ...  \n",
       "9269          None     Alive  No Dual          Taivas       2009         1  \n",
       "9270          None     Alive  No Dual  Battlerealm[1]       2018         1  \n",
       "9271          None     Alive     None            None       2009  Mentions  \n",
       "9272         Black  Deceased  No Dual       Mongolian       2021         1  \n",
       "9273         Black  Deceased  No Dual         Unknown       2020         2  \n",
       "\n",
       "[9274 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df919f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('Marvel Dataframe 2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
