{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce0386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup  \n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import hashlib\n",
    "import time\n",
    "from random import randint\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# public_key='597ec79d6258869ef487f19398a548f3'\n",
    "# private_key = '2a91e39888bc470147b4da008284dc95883bbc06'\n",
    "# ts = time.time()\n",
    "# md = str(ts) + private_key + public_key\n",
    "# hash_md = hashlib.md5(md.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1593dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# marvel_api = 'https://gateway.marvel.com/v1/public/characters?orderBy=name&apikey=' + public_key + '&hash='+ str(hash_md)\n",
    "# page_api = requests.get(marvel_api)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa5f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(page_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a982dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Connection': 'keep-alive',\n",
    "    'sec-ch-ua': '\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"96\", \"Google Chrome\";v=\"96\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'Sec-Fetch-Site': 'none',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-User': '?1',\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Accept-Language': 'he-IL,he;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "}\n",
    "\n",
    "def load_soup_object(url_path):\n",
    "    sleep(randint(3,5))\n",
    "    page = requests.get(url_path ,headers = headers)\n",
    "    print(page)\n",
    "    return BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488418de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## name, current alias, affiliation, marital status, gender,\n",
    "## height, weight, hair color, origin, living status, cause of death, reality, place of birth,\n",
    "## identity, citenzenship, education, creators, unusual features, occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c126837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(columns = ['name', 'current alias', 'affiliation', 'marital status', 'gender', 'hair color',\n",
    "                                    'origin', 'living status', 'reality', 'place of birth',\n",
    "                                    'identity', 'citenzenship', 'education', 'creators', 'occupation'])\n",
    "\n",
    "name_lst = [] \n",
    "current_alias_lst = [] \n",
    "affiliation_lst = [] \n",
    "marital_status_lst = [] \n",
    "gender_lst = []\n",
    "hair_color_lst = [] \n",
    "origin_lst = [] \n",
    "living_status_lst = []\n",
    "reality_lst = []\n",
    "place_of_birth_lst = []\n",
    "identity_lst = [] \n",
    "citenzenship_lst = [] \n",
    "education_lst = []\n",
    "creators_lst = [] \n",
    "occupation_lst = []\n",
    "\n",
    "url_prefix = 'https://marvel.fandom.com'\n",
    "first_page = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfa8e66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup = load_soup_object('https://marvel.fandom.com/wiki/Category:Characters')\n",
    "not_last_page = True\n",
    "while not_last_page:\n",
    "    current_page_character_list = soup.find_all('div', {'class': 'category-page__members-wrapper'})\n",
    "    if first_page:\n",
    "        links = soup.find_all('a',  {'class': 'category-page__member-link'})[18:]\n",
    "        first_page = False\n",
    "    else:\n",
    "        links = soup.find_all('a',  {'class': 'category-page__member-link'})\n",
    "\n",
    "    for i,X in enumerate(links):     \n",
    "        print(str(i) + \". \" + url_prefix + X.get('href'))\n",
    "        character_page_soup = load_soup_object(url_prefix + X.get('href'))\n",
    "        if character_page_soup.find('div',  {'data-source': 'Name'}) is not None:\n",
    "            name_content = character_page_soup.find('div',  {'data-source': 'Name'}).find('div',  {'class': 'pi-data-value pi-font'}).get_text().strip()\n",
    "            name_lst.append(name_content)\n",
    "        else:\n",
    "            name_lst.append(None)\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'CurrentAlias'}) is not None:\n",
    "            alias_content = character_page_soup.find('div',  {'data-source': 'CurrentAlias'}).find('div',  {'class': 'pi-data-value pi-font'}).get_text().strip()\n",
    "            current_alias_lst.append(alias_content)\n",
    "        else:\n",
    "            current_alias_lst.append(None)\n",
    "\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Affiliation'}) is not None:\n",
    "            aff_content = character_page_soup.find('div',  {'data-source': 'Affiliation'}).find('div',  {'class': 'pi-data-value pi-font'}).get_text().strip()\n",
    "            affiliation_lst.append(aff_content)\n",
    "        else:\n",
    "            affiliation_lst.append(None)\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'MaritalStatus'}) is not None:\n",
    "            marital_status_string = \"\"\n",
    "            for x in character_page_soup.find('div', {'data-source': 'MaritalStatus'}).find_all('a'):\n",
    "                marital_status_string += str(x.text) + \" \"\n",
    "\n",
    "            marital_status_lst.append(marital_status_string)\n",
    "        else:\n",
    "            marital_status_lst.append(None)\n",
    "\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Reality'}) is not None: \n",
    "            reality_string = \"\"\n",
    "            for x in character_page_soup.find('div', {'data-source': 'Reality'}).find_all('a'):\n",
    "                reality_string += str(x.text) + \" \"\n",
    "            reality_lst.append(reality_string)\n",
    "        else:\n",
    "            reality_lst.append(None)\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Gender'}) is not None:\n",
    "            gender_string = \"\"\n",
    "            for x in character_page_soup.find('div', {'data-source': 'Gender'}).find_all('a'):\n",
    "                gender_string += str(x.text) + \" \"\n",
    "            gender_lst.append(gender_string)\n",
    "        else:\n",
    "            gender_lst.append(None)\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Hair'}) is not None:\n",
    "            hair_string = \"\"\n",
    "            for x in character_page_soup.find('div', {'data-source': 'Hair'}).find_all('a'):\n",
    "                hair_string += str(x.text) + \" \"\n",
    "            hair_color_lst.append(hair_string)\n",
    "        else:\n",
    "            hair_color_lst.append(None)\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Origin'}) is not None:\n",
    "            origin_string = \"\"\n",
    "            for x in character_page_soup.find('div', {'data-source': 'Origin'}).find_all('a'):\n",
    "                origin_string += str(x.text) + \" \"\n",
    "            origin_lst.append(origin_string)\n",
    "        else:\n",
    "            origin_lst.append(None)\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Status'}) is not None:\n",
    "            status_string = \"\"\n",
    "            for x in character_page_soup.find('div', {'data-source': 'Status'}).find_all('a'):\n",
    "                status_string += str(x.text) + \" \"\n",
    "            living_status_lst.append(status_string)\n",
    "        else:\n",
    "            living_status_lst.append(None)\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'PlaceOfBirth'}) is not None:\n",
    "            birth_string = \"\"\n",
    "            for x in character_page_soup.find('div', {'data-source': 'PlaceOfBirth'}).find_all('a'):\n",
    "                birth_string += str(x.text) + \" \"\n",
    "            place_of_birth_lst.append(birth_string)\n",
    "        else:\n",
    "            place_of_birth_lst.append(None)\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Identity'}) is not None:\n",
    "            identity_string = \"\"\n",
    "            for x in character_page_soup.find('div', {'data-source': 'Identity'}).find_all('a'):\n",
    "                identity_string += str(x.text) + \" \"\n",
    "            identity_lst.append(identity_string)\n",
    "        else:\n",
    "            identity_lst.append(None)\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Citizenship'}) is not None:\n",
    "            #test_soup.find('div', {'data-source': 'Citizenship'}).get_text().strip()\n",
    "            citizen_content = character_page_soup.find('div',  {'data-source': 'Citizenship'}).find('div',  {'class': 'pi-data-value pi-font'}).get_text().strip()\n",
    "            citenzenship_lst.append(citizen_content)\n",
    "        else:\n",
    "            citenzenship_lst.append(None)\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Education'}) is not None:\n",
    "            #test_soup.find('div', {'data-source': 'Education'}).a.get_text().strip()\n",
    "            educ_content = character_page_soup.find('div', {'data-source': 'Education'}).find('div',  {'class': 'pi-data-value pi-font'}).get_text().strip()\n",
    "            education_lst.append(educ_content)\n",
    "        else:\n",
    "            education_lst.append(None)\n",
    "\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Occupation'}) is not None:\n",
    "            occu_content = character_page_soup.find('div',  {'data-source': 'Occupation'}).find('div',  {'class': 'pi-data-value pi-font'}).get_text().strip()\n",
    "            occupation_lst.append(occu_content)\n",
    "        else:\n",
    "            occupation_lst.append(None)\n",
    "\n",
    "        if character_page_soup.find('div',  {'data-source': 'Creators'}) is not None:\n",
    "            creator_string = \"\"\n",
    "            for x in character_page_soup.find('div', {'data-source': 'Creators'}).find_all('a'):\n",
    "                creator_string += str (x.text) + \" \"\n",
    "            creators_lst.append(creator_string)\n",
    "        else:\n",
    "            creators_lst.append(None)\n",
    "            \n",
    "    if soup.find('a', {'class':'category-page__pagination-next'}) is not None:\n",
    "        next_page = soup.find('a', {'class':'category-page__pagination-next'}).get('href')\n",
    "        soup = load_soup_object(next_page)\n",
    "    else:\n",
    "        not_last_page = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9e8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['name'] = name_lst\n",
    "dataframe['current alias'] = current_alias_lst\n",
    "dataframe['affiliation'] = affiliation_lst\n",
    "dataframe['marital status'] = marital_status_lst\n",
    "dataframe['gender'] = gender_lst\n",
    "dataframe['hair color'] = hair_color_lst\n",
    "dataframe['origin'] = origin_lst\n",
    "dataframe['living status'] = living_status_lst\n",
    "dataframe['reality'] = reality_lst\n",
    "dataframe['place of birth'] = place_of_birth_lst\n",
    "dataframe['identity'] = identity_lst\n",
    "dataframe['citenzenship'] = citenzenship_lst\n",
    "dataframe['education'] = education_lst\n",
    "dataframe['creators'] = creators_lst\n",
    "dataframe['occupation'] = occupation_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4f8972",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('marvel.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
